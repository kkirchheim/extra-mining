{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atempt to apply Topic modelling via LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd \n",
    "import sys \n",
    "import nltk\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"src\"))\n",
    "import config \n",
    "import utils\n",
    "from gephi.text import StemmingTokenizer\n",
    "\n",
    "path = os.path.join(config.DIR_PROCESSED, \"reviews.pkl\")\n",
    "df = pd.read_pickle(path)\n",
    "\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = utils.get_stop_words()\n",
    "#tokenizer = StemmingTokenizer()\n",
    "tfidf = TfidfVectorizer(max_features=20000, stop_words=stopwords) # , tokenizer=tokenizer)\n",
    "m = tfidf.fit_transform(df[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "lda = LatentDirichletAllocation(n_components=140)\n",
    "\n",
    "lda_matrix = lda.fit_transform(m)\n",
    "\n",
    "\n",
    "print(\"Matrix Type: %s\" % type(lda_matrix))\n",
    "print(\"Matrix Shape: %s\" % str(lda_matrix.shape))\n",
    "\n",
    "\n",
    "matrix_path = os.path.join(config.DIR_INTERIM, \"lda-matrix.pkl\")\n",
    "print(\"Saving LDA matrix to %s\" % matrix_path)\n",
    "with open(matrix_path, \"wb\") as f:\n",
    "    pickle.dump(lda_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "feature_names = tfidf.get_feature_names() # []\n",
    "#names_path = os.path.join(config.DIR_INTERIM, \"feature-names.txt\")\n",
    "#with open(names_path, \"r\") as f:\n",
    "#    for name in f:\n",
    "#        feature_names.append(name)\n",
    "#        \n",
    "print(len(feature_names))\n",
    "print_top_words(lda, feature_names, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
